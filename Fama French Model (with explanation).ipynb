{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Fama French Factors\n",
    "# September 28 2019\n",
    "# Edited by Xinyu LIU\n",
    "# Originally from Qingyi (Freda) Song Drechsler\n",
    "##########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import wrds\n",
    "import psycopg2 \n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import *\n",
    "from pandas.tseries.offsets import *\n",
    "from pandas.core.frame import DataFrame\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "###################\n",
    "# Connect to WRDS #\n",
    "###################\n",
    "db = wrds.Connection(wrds_username='dachxiu')\n",
    "#make it a constant portal by creating ppass\n",
    "\n",
    "###################\n",
    "# Compustat Block #\n",
    "###################\n",
    "comp = conn.raw_sql(\"\"\"\n",
    "                    select gvkey, datadate, at, pstkl, txditc,\n",
    "                    pstkrv, seq, pstk\n",
    "                    from comp.funda\n",
    "                    where indfmt='INDL' \n",
    "                    and datafmt='STD'\n",
    "                    and popsrc='D'\n",
    "                    and consol='C'\n",
    "                    and datadate >= '01/01/1959'\n",
    "                    \"\"\")\n",
    "#ctrl+/ make comments for multiple lines\n",
    "##################\n",
    "# Meanings of variables\n",
    "##################\n",
    "# gvkey \tChar\t6\tGlobal Company Key\n",
    "# datadate \tNum\t8\tData Date\n",
    "# at \tNum\t8\tAssets - Total\n",
    "# pstkl \tNum\t8\tPreferred Stock - Liquidating Value\n",
    "# txditc \tNum\t8\tDeferred Taxes and Investment Tax Credit\n",
    "# pstkrv \tNum\t8\tPreferred Stock - Redemption Value\n",
    "# seq \tNum\t8\tStockholders Equity - Parent\n",
    "# pstk \tNum\t8\tPreferred/Preference Stock (Capital) - Total\n",
    "\n",
    "#convert datadate to date fmt\n",
    "comp['datadate']=pd.to_datetime(comp['datadate']) \n",
    "comp['year']=comp['datadate'].dt.year\n",
    "#eg:from 2015-02-04（dtype: object） to 2015-02-04(datetime64[ns])\n",
    "#create a new column for 'year'\n",
    "\n",
    "\n",
    "# create preferrerd stock\n",
    "comp['ps']=np.where(comp['pstkrv'].isnull(), comp['pstkl'], comp['pstkrv'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),comp['pstk'], comp['ps'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),0,comp['ps'])\n",
    "#manipulate ps data in the sequense of redemption, liquidating and total value, last resolution is 0\n",
    "\n",
    "comp['txditc']=comp['txditc'].fillna(0)\n",
    "\n",
    "# create book equity\n",
    "comp['be']=comp['seq']+comp['txditc']-comp['ps']\n",
    "comp['be']=np.where(comp['be']>0, comp['be'], np.nan)\n",
    "#Book value of equity equals to Stockholders Equity + Stockholders Equity - Preferred Stocks \n",
    "#set nan value for book equity that is less than 0\n",
    "\n",
    "# number of years in Compustat\n",
    "comp=comp.sort_values(by=['gvkey','datadate'])\n",
    "comp['count']=comp.groupby(['gvkey']).cumcount()\n",
    "#Sort DataFrame by column gvkey and datadate\n",
    "#Mark cumulative number of each gvkey as of that row, starting from 0\n",
    "\n",
    "comp=comp[['gvkey','datadate','year','be','count']]\n",
    "\n",
    "###################\n",
    "# CRSP Block      #\n",
    "###################\n",
    "# sql similar to crspmerge macro\n",
    "crsp_m = conn.raw_sql(\"\"\"\n",
    "                      select a.permno, a.permco, a.date, b.shrcd, b.exchcd,\n",
    "                      a.ret, a.retx, a.shrout, a.prc\n",
    "                      from crsp.msf as a\n",
    "                      left join crsp.msenames as b\n",
    "                      on a.permno=b.permno\n",
    "                      and b.namedt<=a.date\n",
    "                      and a.date<=b.nameendt\n",
    "                      where a.date between '01/01/1959' and '12/31/2017'\n",
    "                      and b.exchcd between 1 and 3\n",
    "                      \"\"\") \n",
    "#crsp.msf refers to Monthly Stock File: Monthly Stock - Securities\n",
    "#crsp.msenames refers to CRSP Monthly Stock Event - Name History\n",
    "#PERMNO \tNum\t8\tPERMNO,PERMNO is a unique five-digit permanent identifier assigned by CRSP to each security in the file\n",
    "#PERMCO \tNum\t8\tPERMCO,PERMCO is a unique permanent identifier assigned by CRSP to all companies with issues on a CRSP file\n",
    "#DATE \tNum\t4\tDate of Observation,DATE is the date corresponding to CAPV and YEAR\n",
    "#RET \tNum\t8\tReturns,A return is the change in the total value of an investment in a common stock over some period of time per dollar of initial investment.\n",
    "#RETX \tNum\t8\tReturns without Dividends, Ordinary dividends and certain other regularly taxable dividends are excluded from the returns calculation. The formula is the same as for RET except d(t) is usually 0\n",
    "#SHROUT \tNum\t8\tShares Outstanding,SHROUT is the number of publicly held shares, recorded in thousands\n",
    "#PRC \tNum\t8\tPrice or Bid/Ask Average,Prc is the closing price or the negative bid/ask average for a trading day.\n",
    "\n",
    "#SHRCD \tNum\t8\tShare Code\n",
    "#EXCHCD \tNum\t8\tExchange Code\n",
    "#NAMEDT \tNum\t8\tNames Date\n",
    "#NAMEENDT \tNum\t8\tNames Ending Date\n",
    "\n",
    "#The left join treats one table—the left table—as the primary dataset for the join. \n",
    "#This means that every row from the left table will be in the result set, \n",
    "#even if there’s no rating from the right table. Below, I’ve highlighted the rows that the left join will return.\n",
    "\n",
    "# change variable format to int\n",
    "crsp_m[['permco','permno','shrcd','exchcd']]=crsp_m[['permco','permno','shrcd','exchcd']].astype(int)\n",
    "\n",
    "# Line up date to be end of month\n",
    "crsp_m['date']=pd.to_datetime(crsp_m['date'])\n",
    "crsp_m['jdate']=crsp_m['date']+MonthEnd(0)\n",
    "#The 1 in MonthEnd just specifies to move one step forward to the next date that's a month end.\n",
    "\n",
    "# add delisting return\n",
    "dlret = conn.raw_sql(\"\"\"\n",
    "                     select permno, dlret, dlstdt \n",
    "                     from crsp.msedelist\n",
    "                     \"\"\")\n",
    "#MSEDELIST\t\tCRSP Monthly Stock Event - Delisting\n",
    "#DLRET \tNum\t8\tDelisting Return,DLRET is the return of the security after it is delisted. \n",
    "#It is calculated by comparing a value after delisting against the price on the security's last trading date. \n",
    "#The value after delisting can include a delisting price or the amount from a final distribution.\n",
    "#DLSTDT \tNum\t8\tDelisting Date,DLSTDT contains the date (in YYMMDD format) of a security's last price on the current exchange.\n",
    "\n",
    "#process dlret\n",
    "dlret.permno=dlret.permno.astype(int)\n",
    "dlret['dlstdt']=pd.to_datetime(dlret['dlstdt'])\n",
    "dlret['jdate']=dlret['dlstdt']+MonthEnd(0)\n",
    "\n",
    "#merge dlret and crsp_m\n",
    "crsp = pd.merge(crsp_m, dlret, how='left',on=['permno','jdate'])\n",
    "#crsp and dlret share the same column names: permno and jdate\n",
    "\n",
    "#process crsp\n",
    "crsp['dlret']=crsp['dlret'].fillna(0)\n",
    "crsp['ret']=crsp['ret'].fillna(0)\n",
    "crsp['retadj']=(1+crsp['ret'])*(1+crsp['dlret'])-1\n",
    "\n",
    "# calculate market equity\n",
    "crsp['me']=crsp['prc'].abs()*crsp['shrout'] \n",
    "#market equity equals to price of stock times shares of outstanding\n",
    "\n",
    "#process crsp\n",
    "crsp=crsp.drop(['dlret','dlstdt','prc','shrout'], axis=1)\n",
    "crsp=crsp.sort_values(by=['jdate','permco','me'])\n",
    "\n",
    "### Aggregate Market Cap ###\n",
    "# sum of me across different permno belonging to same permco a given date\n",
    "crsp_summe = crsp.groupby(['jdate','permco'])['me'].sum().reset_index()\n",
    "# largest mktcap within a permco/date\n",
    "crsp_maxme = crsp.groupby(['jdate','permco'])['me'].max().reset_index()\n",
    "# join by jdate/maxme to find the permno\n",
    "crsp1=pd.merge(crsp, crsp_maxme, how='inner', on=['jdate','permco','me'])\n",
    "# drop me column and replace with the sum me\n",
    "crsp1=crsp1.drop(['me'], axis=1)\n",
    "# join with sum of me to get the correct market cap info\n",
    "crsp2=pd.merge(crsp1, crsp_summe, how='inner', on=['jdate','permco'])\n",
    "# sort by permno and date and also drop duplicates\n",
    "crsp2=crsp2.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "# important to have a duplicate check\n",
    "\n",
    "# keep December market cap\n",
    "crsp2['year']=crsp2['jdate'].dt.year\n",
    "crsp2['month']=crsp2['jdate'].dt.month\n",
    "decme=crsp2[crsp2['month']==12]\n",
    "decme=decme[['permno','date','jdate','me','year']].rename(columns={'me':'dec_me'})\n",
    "\n",
    "### July to June dates\n",
    "crsp2['ffdate']=crsp2['jdate']+MonthEnd(-6)\n",
    "crsp2['ffyear']=crsp2['ffdate'].dt.year\n",
    "crsp2['ffmonth']=crsp2['ffdate'].dt.month\n",
    "crsp2['1+retx']=1+crsp2['retx']\n",
    "crsp2=crsp2.sort_values(by=['permno','date'])\n",
    "\n",
    "# cumret by stock\n",
    "crsp2['cumretx']=crsp2.groupby(['permno','ffyear'])['1+retx'].cumprod()\n",
    "#cumprod returns the product of the year in this case, which is the cumulative return as time goes by\n",
    "\n",
    "# lag cumret\n",
    "crsp2['lcumretx']=crsp2.groupby(['permno'])['cumretx'].shift(1)\n",
    "\n",
    "# lag market cap\n",
    "crsp2['lme']=crsp2.groupby(['permno'])['me'].shift(1)\n",
    "\n",
    "# if first permno then use me/(1+retx) to replace the missing value\n",
    "crsp2['count']=crsp2.groupby(['permno']).cumcount()\n",
    "crsp2['lme']=np.where(crsp2['count']==0, crsp2['me']/crsp2['1+retx'], crsp2['lme'])\n",
    "\n",
    "# baseline me\n",
    "mebase=crsp2[crsp2['ffmonth']==1][['permno','ffyear', 'lme']].rename(columns={'lme':'mebase'})\n",
    "\n",
    "# merge result back together\n",
    "crsp3=pd.merge(crsp2, mebase, how='left', on=['permno','ffyear'])\n",
    "crsp3['wt']=np.where(crsp3['ffmonth']==1, crsp3['lme'], crsp3['mebase']*crsp3['lcumretx'])\n",
    "\n",
    "decme['year']=decme['year']+1\n",
    "decme=decme[['permno','year','dec_me']]\n",
    "\n",
    "# Info as of June\n",
    "crsp3_jun = crsp3[crsp3['month']==6]\n",
    "\n",
    "crsp_jun = pd.merge(crsp3_jun, decme, how='inner', on=['permno','year'])\n",
    "crsp_jun=crsp_jun[['permno','date', 'jdate', 'shrcd','exchcd','retadj','me','wt','cumretx','mebase','lme','dec_me']]\n",
    "crsp_jun=crsp_jun.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "\n",
    "#######################\n",
    "# CCM Block           #\n",
    "#######################\n",
    "ccm=conn.raw_sql(\"\"\"\n",
    "                  select gvkey, lpermno as permno, linktype, linkprim, \n",
    "                  linkdt, linkenddt\n",
    "                  from crsp.ccmxpf_linktable\n",
    "                  where substr(linktype,1,1)='L'\n",
    "                  and (linkprim ='C' or linkprim='P')\n",
    "                  \"\"\")\n",
    "#CCMXPF_LINKTABLE\t\tCRSP/COMPUSTAT Merged - Link History w/ Used Flag\n",
    "#lpermno \tNum\t8\tHistorical CRSP PERMNO Link to COMPUSTAT Record\n",
    "# linktype \tChar\t2\tLink Type Code,\n",
    "# Link Type Code is a 2-character code providing additional detail on the usage of the link data available.\n",
    "# linkprim \tChar\t1\tPrimary Link Marker\n",
    "# linkdt \tNum\t8\tFirst Effective Date of Link\n",
    "# linkenddt \tNum\t8\tLast Effective Date of Link\n",
    "\n",
    "ccm['linkdt']=pd.to_datetime(ccm['linkdt'])\n",
    "ccm['linkenddt']=pd.to_datetime(ccm['linkenddt'])\n",
    "# if linkenddt is missing then set to today date\n",
    "ccm['linkenddt']=ccm['linkenddt'].fillna(pd.to_datetime('today'))\n",
    "#attention: pd.to.datetime does not convert today(M8[ns]) into format '%Y\\%m\\%d', need to go with ccm[].dt.date\n",
    "# eg: ccm['linkenddt']=ccm['linkenddt'].dt.date\n",
    "\n",
    "ccm1=pd.merge(comp[['gvkey','datadate','be', 'count']],ccm,how='left',on=['gvkey'])\n",
    "ccm1['yearend']=ccm1['datadate']+YearEnd(0)\n",
    "ccm1['jdate']=ccm1['yearend']+MonthEnd(6)\n",
    "\n",
    "# set link date bounds\n",
    "ccm2=ccm1[(ccm1['jdate']>=ccm1['linkdt'])&(ccm1['jdate']<=ccm1['linkenddt'])]\n",
    "ccm2=ccm2[['gvkey','permno','datadate','yearend', 'jdate','be', 'count']]\n",
    "\n",
    "# link comp and crsp\n",
    "ccm_jun=pd.merge(crsp_jun, ccm2, how='inner', on=['permno', 'jdate'])\n",
    "ccm_jun['beme']=ccm_jun['be']*1000/ccm_jun['dec_me']\n",
    "\n",
    "# select NYSE stocks for bucket breakdown\n",
    "# exchcd = 1 and positive beme and positive me and shrcd in (10,11) and at least 2 years in comp\n",
    "nyse=ccm_jun[(ccm_jun['exchcd']==1) & (ccm_jun['beme']>0) & (ccm_jun['me']>0) & (ccm_jun['count_y']>1) & ((ccm_jun['shrcd']==10) | (ccm_jun['shrcd']==11))]\n",
    "#####\n",
    "# Important to adjust: both crsp_jun and ccm2 contain 'count' and they are of different values, \n",
    "# therefore there appear to be two columns in the new set ccm_jun.\n",
    "# So the code right above has to specify which 'count' to use\n",
    "# Here I choose 'count_y'\n",
    "#####\n",
    "# size breakdown\n",
    "nyse_sz=nyse.groupby(['jdate'])['me'].median().to_frame().reset_index().rename(columns={'me':'sizemedn'})\n",
    "# beme breakdown\n",
    "nyse_bm=nyse.groupby(['jdate'])['beme'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_bm=nyse_bm[['jdate','30%','70%']].rename(columns={'30%':'bm30', '70%':'bm70'})\n",
    "\n",
    "nyse_breaks = pd.merge(nyse_sz, nyse_bm, how='inner', on=['jdate'])\n",
    "# join back size and beme breakdown\n",
    "ccm1_jun = pd.merge(ccm_jun, nyse_breaks, how='left', on=['jdate'])\n",
    "\n",
    "\n",
    "# function to assign sz and bm bucket\n",
    "def sz_bucket(row):\n",
    "    if row['me']==np.nan:\n",
    "        value=''\n",
    "    elif row['me']<=row['sizemedn']:\n",
    "        value='S'\n",
    "    else:\n",
    "        value='B'\n",
    "    return value\n",
    "\n",
    "def bm_bucket(row):\n",
    "    if 0<=row['beme']<=row['bm30']:\n",
    "        value = 'L'\n",
    "    elif row['beme']<=row['bm70']:\n",
    "        value='M'\n",
    "    elif row['beme']>row['bm70']:\n",
    "        value='H'\n",
    "    else:\n",
    "        value=''\n",
    "    return value\n",
    "\n",
    "# assign size portfolio\n",
    "ccm1_jun['szport']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count_y']>=1), ccm1_jun.apply(sz_bucket, axis=1), '')\n",
    "# assign book-to-market portfolio\n",
    "ccm1_jun['bmport']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count_y']>=1), ccm1_jun.apply(bm_bucket, axis=1), '')\n",
    "# create positivebmeme and nonmissport variable\n",
    "ccm1_jun['posbm']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count_y']>=1), 1, 0)\n",
    "ccm1_jun['nonmissport']=np.where((ccm1_jun['bmport']!=''), 1, 0)\n",
    "\n",
    "#############\n",
    "#Attention!! the 'count' above need to be adjusted to 'count_y' in order to get it run successfully\n",
    "#############\n",
    "\n",
    "# store portfolio assignment as of June\n",
    "june=ccm1_jun[['permno','date', 'jdate', 'bmport','szport','posbm','nonmissport']]\n",
    "june['ffyear']=june['jdate'].dt.year\n",
    "\n",
    "# merge back with monthly records\n",
    "crsp3 = crsp3[['date','permno','shrcd','exchcd','retadj','me','wt','cumretx','ffyear','jdate']]\n",
    "ccm3=pd.merge(crsp3, \n",
    "        june[['permno','ffyear','szport','bmport','posbm','nonmissport']], how='left', on=['permno','ffyear'])\n",
    "\n",
    "# keeping only records that meet the criteria\n",
    "ccm4=ccm3[(ccm3['wt']>0)& (ccm3['posbm']==1) & (ccm3['nonmissport']==1) & \n",
    "          ((ccm3['shrcd']==10) | (ccm3['shrcd']==11))]\n",
    "\n",
    "############################\n",
    "# Form Fama French Factors #\n",
    "############################\n",
    "\n",
    "# function to calculate value weighted return\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "# value-weigthed return\n",
    "vwret=ccm4.groupby(['jdate','szport','bmport']).apply(wavg, 'retadj','wt').to_frame().reset_index().rename(columns={0: 'vwret'})\n",
    "vwret['sbport']=vwret['szport']+vwret['bmport']\n",
    "\n",
    "# firm count\n",
    "vwret_n=ccm4.groupby(['jdate','szport','bmport'])['retadj'].count().reset_index().rename(columns={'retadj':'n_firms'})\n",
    "vwret_n['sbport']=vwret_n['szport']+vwret_n['bmport']\n",
    "\n",
    "# tranpose\n",
    "ff_factors=vwret.pivot(index='jdate', columns='sbport', values='vwret').reset_index()\n",
    "ff_nfirms=vwret_n.pivot(index='jdate', columns='sbport', values='n_firms').reset_index()\n",
    "\n",
    "# create SMB and HML factors\n",
    "ff_factors['WH']=(ff_factors['BH']+ff_factors['SH'])/2\n",
    "ff_factors['WL']=(ff_factors['BL']+ff_factors['SL'])/2\n",
    "ff_factors['WHML'] = ff_factors['WH']-ff_factors['WL']\n",
    "\n",
    "ff_factors['WB']=(ff_factors['BL']+ff_factors['BM']+ff_factors['BH'])/3\n",
    "ff_factors['WS']=(ff_factors['SL']+ff_factors['SM']+ff_factors['SH'])/3\n",
    "ff_factors['WSMB'] = ff_factors['WS']-ff_factors['WB']\n",
    "ff_factors=ff_factors.rename(columns={'jdate':'date'})\n",
    "\n",
    "# n firm count\n",
    "ff_nfirms['H']=ff_nfirms['SH']+ff_nfirms['BH']\n",
    "ff_nfirms['L']=ff_nfirms['SL']+ff_nfirms['BL']\n",
    "ff_nfirms['HML']=ff_nfirms['H']+ff_nfirms['L']\n",
    "\n",
    "ff_nfirms['B']=ff_nfirms['BL']+ff_nfirms['BM']+ff_nfirms['BH']\n",
    "ff_nfirms['S']=ff_nfirms['SL']+ff_nfirms['SM']+ff_nfirms['SH']\n",
    "ff_nfirms['SMB']=ff_nfirms['B']+ff_nfirms['S']\n",
    "ff_nfirms['TOTAL']=ff_nfirms['SMB']\n",
    "ff_nfirms=ff_nfirms.rename(columns={'jdate':'date'})\n",
    "\n",
    "###################\n",
    "# Compare With FF #\n",
    "###################\n",
    "_ff = conn.get_table(library='ff', table='factors_monthly')\n",
    "_ff=_ff[['date','smb','hml']]\n",
    "_ff['date']=_ff['date']+MonthEnd(0)\n",
    "\n",
    "_ffcomp = pd.merge(_ff, ff_factors[['date','WSMB','WHML']], how='inner', on=['date'])\n",
    "_ffcomp70=_ffcomp[_ffcomp['date']>='01/01/1970']\n",
    "print(stats.pearsonr(_ffcomp70['smb'], _ffcomp70['WSMB']))\n",
    "print(stats.pearsonr(_ffcomp70['hml'], _ffcomp70['WHML']))\n",
    "\n",
    "#Print out the above result in a formal way\n",
    "mydata=[stats.pearsonr(_ffcomp70['smb'], _ffcomp70['WSMB']),stats.pearsonr(_ffcomp70['hml'], _ffcomp70['WHML'])]\n",
    "mydata\n",
    "a=DataFrame(mydata, index=['SMB','HML'], columns=['correlation coefficient','p value'])\n",
    "a\n",
    "\n",
    "###################\n",
    "# Visualization of comparison #\n",
    "###################\n",
    "#You may wanna change the data range in the future for case by case use\n",
    "\n",
    "plt.figure(figsize=(12,8)) \n",
    "plt.suptitle(\"Comparison of Results\", fontsize=14)\n",
    "\n",
    "ax1=plt.subplot(2, 1, 1)\n",
    "plt.ylabel(\"Return\")\n",
    "plt.title(\"SMB\")\n",
    "plt.plot(_ffcomp70['date'],_ffcomp70['smb'],label = 'smb',color='red')\n",
    "plt.plot(_ffcomp70['date'],_ffcomp70['WSMB'], label = 'WSMB',color='blue')\n",
    "plt.legend(loc=\"best\")\n",
    "ax1.set_xlim([datetime.date(1972, 7, 31), datetime.date(2018, 12, 31)])\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "ax2=plt.subplot(2, 1, 2)\n",
    "plt.xlabel('Time(y)')\n",
    "plt.ylabel(\"Return\")\n",
    "plt.title(\"HML\")\n",
    "plt.plot(_ffcomp70['date'],_ffcomp70['hml'],label = 'hml', color='red')\n",
    "plt.plot(_ffcomp70['date'],_ffcomp70['WHML'],label = 'WHML', color='blue')\n",
    "ax2.set_xlim([datetime.date(1972, 7, 31), datetime.date(2018, 12, 31)])\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
