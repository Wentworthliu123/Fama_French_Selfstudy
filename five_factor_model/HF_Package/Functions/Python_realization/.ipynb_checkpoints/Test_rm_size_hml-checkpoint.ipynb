{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#coding=utf-8\n",
    "\n",
    "#the first line is necessary to run this code on server\n",
    "##########################################\n",
    "# Fama French Factors -- Daily portfolio for a given month\n",
    "# Nov 7 2019\n",
    "# Created by Xinyu LIU\n",
    "# This program is created to generate all factor daily portfolio for any given month. \n",
    "# The output can then be used to perform intraday calculation.\n",
    "##########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import wrds\n",
    "import psycopg2 \n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import *\n",
    "from pandas.tseries.offsets import *\n",
    "from pandas.core.frame import DataFrame\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "###################\n",
    "# Connect to WRDS #\n",
    "###################\n",
    "conn = wrds.Connection(wrds_username='dachxiu')\n",
    "#make it a constant portal by creating ppass\n",
    "\n",
    "###################\n",
    "# Compustat Block #\n",
    "###################\n",
    "comp = conn.raw_sql(\"\"\"\n",
    "                    select gvkey, datadate, at, pstkl, txditc,pstkrv, pstk, seq,\n",
    "                    lt, ceq, revt, cogs, xsga, xint\n",
    "                    from comp.funda\n",
    "                    where indfmt='INDL' \n",
    "                    and datafmt='STD'\n",
    "                    and popsrc='D'\n",
    "                    and consol='C'\n",
    "                    and datadate >= '01/01/2012'\n",
    "                    \"\"\")\n",
    "#ctrl+/ make comments for multiple lines\n",
    "##################\n",
    "# Meanings of variables\n",
    "##################\n",
    "# gvkey \tChar\t6\tGlobal Company Key\n",
    "# datadate \tNum\t8\tData Date\n",
    "# at \tNum\t8\tAssets - Total\n",
    "# pstkl \tNum\t8\tPreferred Stock - Liquidating Value\n",
    "# txditc \tNum\t8\tDeferred Taxes and Investment Tax Credit\n",
    "# pstkrv \tNum\t8\tPreferred Stock - Redemption Value\n",
    "# seq \tNum\t8\tStockholders Equity - Parent\n",
    "# pstk \tNum\t8\tPreferred/Preference Stock (Capital) - Total\n",
    "\n",
    "#convert datadate to date fmt\n",
    "comp['datadate']=pd.to_datetime(comp['datadate']) \n",
    "comp['year']=comp['datadate'].dt.year\n",
    "#eg:from 2015-02-04锛坉type: object锛?to 2015-02-04(datetime64[ns])\n",
    "#create a new column for 'year'\n",
    "\n",
    "\n",
    "# create preferrerd stock\n",
    "comp['ps']=np.where(comp['pstkrv'].isnull(), comp['pstkl'], comp['pstkrv'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),comp['pstk'], comp['ps'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),0,comp['ps'])\n",
    "#manipulate ps data in the sequense of redemption, liquidating and total value, last resolution is 0\n",
    "\n",
    "comp['txditc']=comp['txditc'].fillna(0)\n",
    "\n",
    "# create book equity\n",
    "comp['be']=comp['seq']+comp['txditc']-comp['ps']\n",
    "comp['be']=np.where(comp['be']>0, comp['be'], np.nan)\n",
    "# create operating profit\n",
    "comp['revt']=comp['revt'].fillna(0)\n",
    "comp['cogs']=comp['cogs'].fillna(0)\n",
    "comp['xsga']=comp['xsga'].fillna(0)\n",
    "comp['xint']=comp['xint'].fillna(0)\n",
    "comp['op']=np.where(comp['be']>0, (comp['revt']-comp['cogs']-comp['xsga']-comp['xint'])/comp['be'], np.nan)\n",
    "# create investment\n",
    "comp['lat']=comp.sort_values(by=['datadate'], ascending=True).groupby(['gvkey'])['at'].shift(1)\n",
    "comp['inv']=(comp['lat']-comp['at'])/comp['at']\n",
    "\n",
    "\n",
    "# number of years in Compustat\n",
    "comp=comp.sort_values(by=['gvkey','datadate'])\n",
    "comp['count']=comp.groupby(['gvkey']).cumcount()\n",
    "#Sort DataFrame by column gvkey and datadate\n",
    "#Mark cumulative number of each gvkey as of that row, starting from 0\n",
    "\n",
    "comp=comp[['gvkey','datadate','year','be','op','inv','count']]\n",
    "\n",
    "###################\n",
    "# CRSP Block      #\n",
    "###################\n",
    "# sql similar to crspmerge macro\n",
    "crsp_m = conn.raw_sql(\"\"\"\n",
    "                      select a.permno, a.permco, a.date, b.shrcd, b.exchcd,\n",
    "                      a.ret, a.retx, a.shrout, a.prc\n",
    "                      from crsp.msf as a\n",
    "                      left join crsp.msenames as b\n",
    "                      on a.permno=b.permno\n",
    "                      and b.namedt<=a.date\n",
    "                      and a.date<=b.nameendt\n",
    "                      where a.date between '07/01/2012' and '06/30/2016'\n",
    "                      and b.exchcd between 1 and 3\n",
    "                      \"\"\") \n",
    "#crsp.msf refers to Monthly Stock File: Monthly Stock - Securities\n",
    "#crsp.msenames refers to CRSP Monthly Stock Event - Name History\n",
    "#PERMNO \tNum\t8\tPERMNO,PERMNO is a unique five-digit permanent identifier assigned by CRSP to each security in the file\n",
    "#PERMCO \tNum\t8\tPERMCO,PERMCO is a unique permanent identifier assigned by CRSP to all companies with issues on a CRSP file\n",
    "#DATE \tNum\t4\tDate of Observation,DATE is the date corresponding to CAPV and YEAR\n",
    "#RET \tNum\t8\tReturns,A return is the change in the total value of an investment in a common stock over some period of time per dollar of initial investment.\n",
    "#RETX \tNum\t8\tReturns without Dividends, Ordinary dividends and certain other regularly taxable dividends are excluded from the returns calculation. The formula is the same as for RET except d(t) is usually 0\n",
    "#SHROUT \tNum\t8\tShares Outstanding,SHROUT is the number of publicly held shares, recorded in thousands\n",
    "#PRC \tNum\t8\tPrice or Bid/Ask Average,Prc is the closing price or the negative bid/ask average for a trading day.\n",
    "\n",
    "#SHRCD \tNum\t8\tShare Code\n",
    "#EXCHCD \tNum\t8\tExchange Code\n",
    "#NAMEDT \tNum\t8\tNames Date\n",
    "#NAMEENDT \tNum\t8\tNames Ending Date\n",
    "\n",
    "#The left join treats one table鈥攖he left table鈥攁s the primary dataset for the join. \n",
    "#This means that every row from the left table will be in the result set, \n",
    "#even if there鈥檚 no rating from the right table. Below, I鈥檝e highlighted the rows that the left join will return.\n",
    "\n",
    "# change variable format to int\n",
    "crsp_m[['permco','permno','shrcd','exchcd']]=crsp_m[['permco','permno','shrcd','exchcd']].astype(int)\n",
    "\n",
    "# Line up date to be end of month\n",
    "crsp_m['date']=pd.to_datetime(crsp_m['date'])\n",
    "crsp_m['jdate']=crsp_m['date']+MonthEnd(0)\n",
    "#The 1 in MonthEnd just specifies to move one step forward to the next date that's a month end.\n",
    "\n",
    "# add delisting return\n",
    "dlret = conn.raw_sql(\"\"\"\n",
    "                     select permno, dlret, dlstdt \n",
    "                     from crsp.msedelist\n",
    "                     \"\"\")\n",
    "#MSEDELIST\t\tCRSP Monthly Stock Event - Delisting\n",
    "#DLRET \tNum\t8\tDelisting Return,DLRET is the return of the security after it is delisted. \n",
    "#It is calculated by comparing a value after delisting against the price on the security's last trading date. \n",
    "#The value after delisting can include a delisting price or the amount from a final distribution.\n",
    "#DLSTDT \tNum\t8\tDelisting Date,DLSTDT contains the date (in YYMMDD format) of a security's last price on the current exchange.\n",
    "\n",
    "#process dlret\n",
    "dlret.permno=dlret.permno.astype(int)\n",
    "dlret['dlstdt']=pd.to_datetime(dlret['dlstdt'])\n",
    "dlret['jdate']=dlret['dlstdt']+MonthEnd(0)\n",
    "\n",
    "#merge dlret and crsp_m\n",
    "crsp = pd.merge(crsp_m, dlret, how='left',on=['permno','jdate'])\n",
    "#crsp and dlret share the same column names: permno and jdate\n",
    "\n",
    "#process crsp\n",
    "crsp['dlret']=crsp['dlret'].fillna(0)\n",
    "crsp['ret']=crsp['ret'].fillna(0)\n",
    "crsp['retadj']=(1+crsp['ret'])*(1+crsp['dlret'])-1\n",
    "\n",
    "# calculate market equity\n",
    "crsp['me']=crsp['prc'].abs()*crsp['shrout'] \n",
    "#market equity equals to price of stock times shares of outstanding\n",
    "\n",
    "#process crsp\n",
    "crsp=crsp.drop(['dlret','dlstdt','prc','shrout'], axis=1)\n",
    "crsp=crsp.sort_values(by=['jdate','permco','me'])\n",
    "\n",
    "### Aggregate Market Cap ###\n",
    "# sum of me across different permno belonging to same permco a given date\n",
    "crsp_summe = crsp.groupby(['jdate','permco'])['me'].sum().reset_index()\n",
    "# largest mktcap within a permco/date\n",
    "crsp_maxme = crsp.groupby(['jdate','permco'])['me'].max().reset_index()\n",
    "# join by jdate/maxme to find the permno\n",
    "crsp1=pd.merge(crsp, crsp_maxme, how='inner', on=['jdate','permco','me'])\n",
    "# drop me column and replace with the sum me\n",
    "crsp1=crsp1.drop(['me'], axis=1)\n",
    "# join with sum of me to get the correct market cap info\n",
    "crsp2=pd.merge(crsp1, crsp_summe, how='inner', on=['jdate','permco'])\n",
    "# sort by permno and date and also drop duplicates\n",
    "crsp2=crsp2.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "# important to have a duplicate check\n",
    "\n",
    "# keep December market cap\n",
    "crsp2['year']=crsp2['jdate'].dt.year\n",
    "crsp2['month']=crsp2['jdate'].dt.month\n",
    "decme=crsp2[crsp2['month']==12]\n",
    "decme=decme[['permno','date','jdate','me','year']].rename(columns={'me':'dec_me'})\n",
    "\n",
    "### July to June dates\n",
    "crsp2['ffdate']=crsp2['jdate']+MonthEnd(-6)\n",
    "crsp2['ffyear']=crsp2['ffdate'].dt.year\n",
    "crsp2['ffmonth']=crsp2['ffdate'].dt.month\n",
    "crsp2['1+retx']=1+crsp2['retx']\n",
    "crsp2=crsp2.sort_values(by=['permno','date'])\n",
    "\n",
    "# cumret by stock\n",
    "crsp2['cumretx']=crsp2.groupby(['permno','ffyear'])['1+retx'].cumprod()\n",
    "#cumprod returns the product of the year in this case, which is the cumulative return as time goes by\n",
    "\n",
    "# lag cumret\n",
    "crsp2['lcumretx']=crsp2.groupby(['permno'])['cumretx'].shift(1)\n",
    "\n",
    "# lag market cap\n",
    "crsp2['lme']=crsp2.groupby(['permno'])['me'].shift(1)\n",
    "\n",
    "# if first permno then use me/(1+retx) to replace the missing value\n",
    "crsp2['count']=crsp2.groupby(['permno']).cumcount()\n",
    "crsp2['lme']=np.where(crsp2['count']==0, crsp2['me']/crsp2['1+retx'], crsp2['lme'])\n",
    "\n",
    "# baseline me\n",
    "mebase=crsp2[crsp2['ffmonth']==1][['permno','ffyear', 'lme']].rename(columns={'lme':'mebase'})\n",
    "\n",
    "# merge result back together\n",
    "crsp3=pd.merge(crsp2, mebase, how='left', on=['permno','ffyear'])\n",
    "crsp3['wt']=np.where(crsp3['ffmonth']==1, crsp3['lme'], crsp3['mebase']*crsp3['lcumretx'])\n",
    "\n",
    "decme['year']=decme['year']+1\n",
    "decme=decme[['permno','year','dec_me']]\n",
    "\n",
    "# Info as of June\n",
    "crsp3_jun = crsp3[crsp3['month']==6]\n",
    "\n",
    "crsp_jun = pd.merge(crsp3_jun, decme, how='inner', on=['permno','year'])\n",
    "crsp_jun=crsp_jun[['permno','date', 'jdate', 'shrcd','exchcd','retadj','me','wt','cumretx','mebase','lme','dec_me']]\n",
    "crsp_jun=crsp_jun.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "\n",
    "#######################\n",
    "# CCM Block           #\n",
    "#######################\n",
    "ccm=conn.raw_sql(\"\"\"\n",
    "                  select gvkey, lpermno as permno, linktype, linkprim, \n",
    "                  linkdt, linkenddt\n",
    "                  from crsp.ccmxpf_linktable\n",
    "                  where substr(linktype,1,1)='L'\n",
    "                  and (linkprim ='C' or linkprim='P')\n",
    "                  \"\"\")\n",
    "#CCMXPF_LINKTABLE\t\tCRSP/COMPUSTAT Merged - Link History w/ Used Flag\n",
    "#lpermno \tNum\t8\tHistorical CRSP PERMNO Link to COMPUSTAT Record\n",
    "# linktype \tChar\t2\tLink Type Code,\n",
    "# Link Type Code is a 2-character code providing additional detail on the usage of the link data available.\n",
    "# linkprim \tChar\t1\tPrimary Link Marker\n",
    "# linkdt \tNum\t8\tFirst Effective Date of Link\n",
    "# linkenddt \tNum\t8\tLast Effective Date of Link\n",
    "\n",
    "ccm['linkdt']=pd.to_datetime(ccm['linkdt'])\n",
    "ccm['linkenddt']=pd.to_datetime(ccm['linkenddt'])\n",
    "# if linkenddt is missing then set to today date\n",
    "ccm['linkenddt']=ccm['linkenddt'].fillna(pd.to_datetime('today'))\n",
    "#attention: pd.to.datetime does not convert today(M8[ns]) into format '%Y\\%m\\%d', need to go with ccm[].dt.date\n",
    "# if using the code below there will be warning on server\n",
    "# eg: ccm['linkenddt']=ccm['linkenddt'].dt.date\n",
    "\n",
    "ccm1=pd.merge(comp[['gvkey','datadate','be','op','inv','count']],ccm,how='left',on=['gvkey'])\n",
    "ccm1['yearend']=ccm1['datadate']+YearEnd(0)\n",
    "ccm1['jdate']=ccm1['yearend']+MonthEnd(6)\n",
    "\n",
    "# set link date bounds\n",
    "ccm2=ccm1[(ccm1['jdate']>=ccm1['linkdt'])&(ccm1['jdate']<=ccm1['linkenddt'])]\n",
    "ccm2=ccm2[['gvkey','permno','datadate','yearend','jdate','be','op','inv','count']]\n",
    "\n",
    "# link comp and crsp\n",
    "ccm_jun=pd.merge(crsp_jun, ccm2, how='inner', on=['permno', 'jdate'])\n",
    "ccm_jun['beme']=ccm_jun['be']*1000/ccm_jun['dec_me']\n",
    "\n",
    "# select NYSE stocks for bucket breakdown\n",
    "# exchcd = 1 and positive beme and positive me and shrcd in (10,11) and at least 2 years in comp\n",
    "nyse=ccm_jun[(ccm_jun['exchcd']==1) & (ccm_jun['beme']>0) & (ccm_jun['me']>0) & (ccm_jun['count']>=1) & ((ccm_jun['shrcd']==10) | (ccm_jun['shrcd']==11))]\n",
    "\n",
    "#####\n",
    "# size breakdown\n",
    "nyse_sz=nyse.groupby(['jdate'])['me'].median().to_frame().reset_index().rename(columns={'me':'sizemedn'})\n",
    "# beme breakdown\n",
    "nyse_bm=nyse.groupby(['jdate'])['beme'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_bm=nyse_bm[['jdate','30%','70%']].rename(columns={'30%':'bm30', '70%':'bm70'})\n",
    "# op breakdown\n",
    "nyse_op=nyse.groupby(['jdate'])['op'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_op=nyse_op[['jdate','30%','70%']].rename(columns={'30%':'op30', '70%':'op70'})\n",
    "# inv breakdown\n",
    "nyse_inv=nyse.groupby(['jdate'])['inv'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_inv=nyse_inv[['jdate','30%','70%']].rename(columns={'30%':'inv30', '70%':'inv70'})\n",
    "\n",
    "# join together factor breakdown\n",
    "nyse_breaks_bm = pd.merge(nyse_sz, nyse_bm, how='inner', on=['jdate'])\n",
    "nyse_breaks_op = pd.merge(nyse_breaks_bm, nyse_op, how='inner', on=['jdate'])\n",
    "nyse_breaks_inv = pd.merge(nyse_breaks_op, nyse_inv, how='inner', on=['jdate'])\n",
    "\n",
    "# join back factor breakdown\n",
    "ccm1_jun = pd.merge(ccm_jun, nyse_breaks_inv, how='left', on=['jdate'])\n",
    "\n",
    "\n",
    "# function to assign sz and bm bucket\n",
    "def sz_bucket(row):\n",
    "    if row['me']==np.nan:\n",
    "        value=''\n",
    "    elif row['me']<=row['sizemedn']:\n",
    "        value='S'\n",
    "    else:\n",
    "        value='B'\n",
    "    return value\n",
    "\n",
    "def bm_bucket(row):\n",
    "    if 0<=row['beme']<=row['bm30']:\n",
    "        value = 'L'\n",
    "    elif row['beme']<=row['bm70']:\n",
    "        value='M'\n",
    "    elif row['beme']>row['bm70']:\n",
    "        value='H'\n",
    "    else:\n",
    "        value=''\n",
    "    return value\n",
    "\n",
    "def rw_bucket(row):\n",
    "    if row['op']<=row['op30']:\n",
    "        value = 'W'\n",
    "    elif row['op']<=row['op70']:\n",
    "        value='M'\n",
    "    elif row['op']>row['op70']:\n",
    "        value='R'\n",
    "    else:\n",
    "        value=''\n",
    "    return value\n",
    "\n",
    "def ca_bucket(row):\n",
    "    if row['inv']<=row['inv30']:\n",
    "        value ='A'\n",
    "    elif row['inv']<=row['inv70']:\n",
    "        value='M'\n",
    "    elif row['inv']>row['inv70']:\n",
    "        value='C'\n",
    "    else:\n",
    "        value=''\n",
    "    return value\n",
    "\n",
    "# assign size portfolio\n",
    "ccm1_jun['szport']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count']>=1), ccm1_jun.apply(sz_bucket, axis=1), '')\n",
    "# assign book-to-market portfolio\n",
    "ccm1_jun['bmport']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count']>=1), ccm1_jun.apply(bm_bucket, axis=1), '')\n",
    "# assign operating profit portfolio\n",
    "ccm1_jun['rwport']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count']>=1), ccm1_jun.apply(rw_bucket, axis=1), '')\n",
    "# assign investment portfolio\n",
    "ccm1_jun['caport']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count']>=1), ccm1_jun.apply(ca_bucket, axis=1), '')\n",
    "# create positivebmeme and nonmissport variable\n",
    "ccm1_jun['posbm']=np.where((ccm1_jun['beme']>0)&(ccm1_jun['me']>0)&(ccm1_jun['count']>=1), 1, 0)\n",
    "ccm1_jun['nonmissport_bm']=np.where((ccm1_jun['bmport']!=''), 1, 0)\n",
    "ccm1_jun['nonmissport_rw']=np.where((ccm1_jun['rwport']!=''), 1, 0)\n",
    "ccm1_jun['nonmissport_ca']=np.where((ccm1_jun['caport']!=''), 1, 0)\n",
    "# store portfolio assignment as of June\n",
    "june=ccm1_jun[['permno','date', 'jdate', 'bmport','rwport','szport','caport','posbm','nonmissport_bm','nonmissport_rw','nonmissport_ca']]\n",
    "june['ffyear']=june['jdate'].dt.year\n",
    "\n",
    "#######################################################\n",
    "# Create Momentum Portfolio                           #   \n",
    "# Measures Based on Past (J) Month Compounded Returns #\n",
    "#######################################################\n",
    "J = 11 \n",
    "\n",
    "ccm5=crsp3[(crsp3['wt']>0) & ((crsp3['shrcd']==10) | (crsp3['shrcd']==11))].copy()\n",
    "ccm5['ret']=ccm5['retadj']\n",
    "_tmp_crsp = ccm5[['permno','date','ret','me','exchcd']].sort_values(['permno','date']).set_index('date')\n",
    "# Replace missing return with 0\n",
    "_tmp_crsp['ret']=_tmp_crsp['ret'].fillna(0)\n",
    "# Calculate rolling cumulative return\n",
    "# by summing log(1+ret) over the formation period\n",
    "_tmp_crsp['logret']=np.log(1+_tmp_crsp['ret'])\n",
    "umdr = _tmp_crsp.groupby(['permno','exchcd'])['logret'].rolling(J, min_periods=J).sum()\n",
    "_tmp_crsp=_tmp_crsp.reset_index()\n",
    "_tmp_crsp=_tmp_crsp.drop(columns=['logret'])\n",
    "umdr = umdr.reset_index()\n",
    "umd = pd.merge(_tmp_crsp,umdr,how='left',on=['date','permno','exchcd'])\n",
    "umd['raw_cumret']=np.exp(umd['logret'])-1\n",
    "umd['cumret']=umd.groupby(['permno'])['raw_cumret'].shift(1)\n",
    "umd=umd.dropna(axis=0, subset=['cumret','me'])\n",
    "nysemom=umd[umd['exchcd']==1]\n",
    "\n",
    "nyse_mom=nysemom.groupby(['date'])['cumret'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_mom=nyse_mom[['date','30%','70%']].rename(columns={'30%':'cumret30', '70%':'cumret70'})\n",
    "ccm1_mom = pd.merge(umd, nyse_mom, how='left', on=['date'])\n",
    "\n",
    "def mom_bucket(row):\n",
    "    if row['cumret']<=row['cumret30']:\n",
    "        value = 'L'\n",
    "    elif row['cumret']<=row['cumret70']:\n",
    "        value='M'\n",
    "    elif row['cumret']>row['cumret70']:\n",
    "        value='H'\n",
    "    else:\n",
    "        value=''\n",
    "    return value\n",
    "\n",
    "ccm1_mom['momport']=ccm1_mom.apply(mom_bucket, axis=1)\n",
    "ccm1_mom['momposbm']=np.where((ccm1_mom['me']>0), 1, 0)\n",
    "ccm1_mom['nonmissport_mom']=np.where((ccm1_mom['momport']!=''), 1, 0)\n",
    "ccm1_mom['jdate']=ccm1_mom['date']+MonthEnd(1)\n",
    "everymom=ccm1_mom[['permno','date', 'jdate', 'momport','momposbm','nonmissport_mom']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "# Import daily data #\n",
    "############################\n",
    "\n",
    "crsp_d = conn.raw_sql(\"\"\"\n",
    "                      select a.permno, a.permco, a.date, b.shrcd, b.exchcd,\n",
    "                      a.ret, a.retx, a.shrout, a.prc, a.openprc\n",
    "                      from crsp.dsf as a\n",
    "                      left join crsp.dsenames as b\n",
    "                      on a.permno=b.permno\n",
    "                      and b.namedt<=a.date\n",
    "                      and a.date<=b.nameendt\n",
    "                      where a.date between '09/01/2015' and '09/30/2015'\n",
    "                      and b.exchcd between 1 and 3\n",
    "                      \"\"\") \n",
    "# change variable format to int\n",
    "crsp_d[['permco','permno','shrcd','exchcd']]=crsp_d[['permco','permno','shrcd','exchcd']].astype(int)\n",
    "\n",
    "# Line up date to be end of month\n",
    "crsp_d['date']=pd.to_datetime(crsp_d['date'])\n",
    "#####################\n",
    "crsp_d['jdate']=crsp_d['date']+MonthEnd(0)\n",
    "crsp_d['ffdate']=crsp_d['jdate']+MonthEnd(-6)\n",
    "crsp_d['ffyear']=crsp_d['ffdate'].dt.year\n",
    "#The 1 in MonthEnd just specifies to move one step forward to the next date that's a month end.\n",
    "\n",
    "# add delisting return\n",
    "dlret_d = conn.raw_sql(\"\"\"\n",
    "                     select permno, dlret, dlstdt \n",
    "                     from crsp.dsedelist\n",
    "                     \"\"\")\n",
    "\n",
    "#process dlret\n",
    "dlret_d.permno=dlret_d.permno.astype(int)\n",
    "dlret_d['dlstdt']=pd.to_datetime(dlret_d['dlstdt'])\n",
    "#######################\n",
    "dlret_d['date']=dlret_d['dlstdt']\n",
    "\n",
    "#merge dlret and crsp_m\n",
    "crspd = pd.merge(crsp_d, dlret_d, how='left',on=['permno','date'])\n",
    "#crsp and dlret share the same column names: permno and jdate\n",
    "\n",
    "#process crsp\n",
    "crspd['dlret']=crspd['dlret'].fillna(0)\n",
    "crspd['ret']=crspd['ret'].fillna(0)\n",
    "crspd['retadj']=(1+crspd['ret'])*(1+crspd['dlret'])-1\n",
    "\n",
    "# calculate market equity\n",
    "crspd['me']=crspd['prc'].abs()*crspd['shrout'] \n",
    "#market equity equals to price of stock times shares of outstanding\n",
    "\n",
    "#process crsp\n",
    "#crspd=crspd.drop(['dlret','dlstdt','prc','shrout'], axis=1)\n",
    "crspd=crspd.sort_values(by=['date','permco','me'])\n",
    "\n",
    "### Aggregate Market Cap ###\n",
    "# sum of me across different permno belonging to same permco a given date\n",
    "crspd_summe = crspd.groupby(['date','permco'])['me'].sum().reset_index()\n",
    "# largest mktcap within a permco/date\n",
    "crspd_maxme = crspd.groupby(['date','permco'])['me'].max().reset_index()\n",
    "# join by jdate/maxme to find the permno\n",
    "crspd1=pd.merge(crspd, crspd_maxme, how='inner', on=['date','permco','me'])\n",
    "# drop me column and replace with the sum me\n",
    "crspd1=crspd1.drop(['me'], axis=1)\n",
    "# join with sum of me to get the correct market cap info\n",
    "crspd2=pd.merge(crspd1, crspd_summe, how='inner', on=['date','permco'])\n",
    "# sort by permno and date and also drop duplicates\n",
    "crspd2=crspd2.sort_values(by=['permno','date']).drop_duplicates()\n",
    "# important to have a duplicate check\n",
    "\n",
    "# lag market cap\n",
    "crspd2['lme']=crspd2.groupby(['permno'])['me'].shift(1)\n",
    "\n",
    "# if first permno then use me/(1+retx) to replace the missing value\n",
    "crspd2['count']=crspd2.groupby(['permno']).cumcount()\n",
    "crspd2['lme']=np.where(crspd2['count']==0, crspd2['me']/(1+crspd2['retx']), crspd2['lme'])\n",
    "# baseline me\n",
    "\n",
    "# merge result back together\n",
    "crspd2['wt']=crspd2['lme']\n",
    "\n",
    "# merge back with monthly records\n",
    "crspd2 = crspd2[['date','permno','prc','openprc','shrcd','exchcd','retadj','me','wt','ffyear','jdate','dlret','dlstdt','shrout']]\n",
    "crspd2mom = pd.merge(crspd2, everymom[['permno', 'jdate', 'momport','momposbm','nonmissport_mom']], how='left', on=['permno','jdate'])\n",
    "ccm3=pd.merge(crspd2mom, \n",
    "        june[['permno','ffyear','bmport','rwport','szport','caport','posbm','nonmissport_bm','nonmissport_rw','nonmissport_ca']], how='left', on=['permno','ffyear'])\n",
    "\n",
    "# keeping only records that meet the criteria\n",
    "ccm4=ccm3[(ccm3['wt']>0) & (ccm3['posbm']==1) & (ccm3['momposbm']==1) & ((ccm3['shrcd']==10) | (ccm3['shrcd']==11))]\n",
    "ccm4.to_csv(\"1509_daily_all.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
